{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install piexif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMjVwZT_c9RZ",
        "outputId": "0d1ad1f0-240e-4fc7-9f96-14925ff96203"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting piexif\n",
            "  Downloading piexif-1.1.3-py2.py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading piexif-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: piexif\n",
            "Successfully installed piexif-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dHggYEeMG-ng"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import logging\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import cv2 # OpenCV per lettura/scrittura immagini/video e calcolo nitidezza\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, UnidentifiedImageError # Pillow per gestione EXIF\n",
        "import piexif # Per manipolare EXIF\n",
        "import shutil # Per copiare/muovere file (utile per pulizia e salvataggio frame\n",
        "from types import SimpleNamespace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlLV5FqUcg4c",
        "outputId": "c036af0d-c9d5-4d01-c1fb-54dcec662814"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#     from googleapiclient.discovery import build\n",
        "#     from googleapiclient.errors import HttpError\n",
        "#     from google.oauth2 import service_account\n",
        "#     GOOGLE_LIBS_AVAILABLE = True\n",
        "# except ImportError:\n",
        "#     GOOGLE_LIBS_AVAILABLE = False\n",
        "#     print(\"Librerie Google non trovate. Integrazione Sheets disabilitata.\")\n",
        "\n",
        "# --- Configurazione Percorso Base ---\n",
        "# Prova a montare Drive se in Colab, altrimenti usa percorso locale"
      ],
      "metadata": {
        "id": "fvbJQAApZw0o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CONFIGURAZIONE PARAMETRI GLOBALI\n",
        "IMG_SIZE = (224, 224) # Dimensioni target delle immagini\n",
        "BATCH_SIZE = 32 # Dimensione del batch\n",
        "EPOCHS_HEAD = 8 # Epoche training testa\n",
        "EPOCHS_FINE = 4 # Epoche fine-tuning\n",
        "FRAME_INTERVAL = 1 # Secondi tra frame estratti\n",
        "LEARN_HEAD_LR = 1e-3 # Learning rate testa\n",
        "LEARN_FULL_LR = 1e-4 # Learning rate fine-tuning\n",
        "\n",
        "# Parametri selezione frame video\n",
        "SHARPNESS_THRESHOLD = 80.0 # Soglia nitidezza\n",
        "FRAMES_PER_PLACE_PER_VIDEO = 5 # Max frame da salvare"
      ],
      "metadata": {
        "id": "_Xi_Tb1tZ2FZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GDRIVE_PROJECT_PATH = Path(\"/content/drive/MyDrive/ProgettoClassificazioneLuoghi\")\n",
        "\n",
        "# PERCORSI FILE\n",
        "DEFAULT_TRAIN_DIR = GDRIVE_PROJECT_PATH / \"dataset\" / \"train\"  # Giusto\n",
        "DEFAULT_VAL_DIR = GDRIVE_PROJECT_PATH / \"dataset\" / \"val\"    # Giusto\n",
        "\n",
        "# puntano dentro la cartella 'dataset'\n",
        "# Assicurarsi che i nomi \"inputIMG\" e \"inputVID\" siano corretti\n",
        "# rispetto a come si chiamano DENTRO la cartella 'dataset'\n",
        "DEFAULT_IMG_DIR = GDRIVE_PROJECT_PATH / \"dataset\" / \"inputIMG\"\n",
        "DEFAULT_VID_DIR = GDRIVE_PROJECT_PATH / \"dataset\" / \"inputVID\"\n",
        "\n",
        "DEFAULT_OUTPUT = GDRIVE_PROJECT_PATH / \"output\"\n",
        "DEFAULT_CSV = DEFAULT_OUTPUT / \"results.csv\"\n",
        "PROCESSED_LOG = DEFAULT_OUTPUT / \"processed.log\"\n",
        "BEST_FRAMES_OUTPUT_DIR = DEFAULT_OUTPUT / \"best_frames\"\n",
        "TEMP_FRAME_EXTRACT_DIR = DEFAULT_OUTPUT / \"temp_frames\"\n",
        "\n",
        "# Crea directory di output necessarie\n",
        "DEFAULT_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
        "BEST_FRAMES_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TEMP_FRAME_EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Cartella Immagini Input (Modificata): {DEFAULT_IMG_DIR}\")\n",
        "print(f\"Cartella Video Input (Modificata): {DEFAULT_VID_DIR}\")\n",
        "print(f\"Cartella Output Generale: {DEFAULT_OUTPUT}\")\n",
        "print(f\"Cartella Output Frame Migliori: {BEST_FRAMES_OUTPUT_DIR}\")\n",
        "print(f\"Cartella Output Temporanea Frame: {TEMP_FRAME_EXTRACT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uT3RvzkZ6Hp",
        "outputId": "f9b89776-3986-47fb-8acd-747b92399dc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cartella Immagini Input (Modificata): /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG\n",
            "Cartella Video Input (Modificata): /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputVID\n",
            "Cartella Output Generale: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output\n",
            "Cartella Output Frame Migliori: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/best_frames\n",
            "Cartella Output Temporanea Frame: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/temp_frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "gdrive_base = Path(\"/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset\")\n",
        "img_input_path_test = gdrive_base / \"inputIMG\" # Usa il nome ESATTO della tua cartella\n",
        "vid_input_path_test = gdrive_base / \"inputVID\" # Usa il nome ESATTO della tua cartella\n",
        "\n",
        "print(f\"Verifica percorso immagini: {img_input_path_test}\")\n",
        "print(f\"Esiste? {img_input_path_test.exists()}\")\n",
        "print(f\"È una directory? {img_input_path_test.is_dir()}\")\n",
        "if img_input_path_test.exists() and img_input_path_test.is_dir():\n",
        "    print(f\"Contenuto: {list(img_input_path_test.iterdir())[:5]}\") # Stampa i primi 5 file/cartelle\n",
        "\n",
        "print(f\"\\nVerifica percorso video: {vid_input_path_test}\")\n",
        "print(f\"Esiste? {vid_input_path_test.exists()}\")\n",
        "print(f\"È una directory? {vid_input_path_test.is_dir()}\")\n",
        "if vid_input_path_test.exists() and vid_input_path_test.is_dir():\n",
        "    print(f\"Contenuto: {list(vid_input_path_test.iterdir())[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOTA8epKPABW",
        "outputId": "6ccbed79-de85-4677-b8da-72233ab3e3d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifica percorso immagini: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG\n",
            "Esiste? True\n",
            "È una directory? True\n",
            "Contenuto: [PosixPath('/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (2).jpg'), PosixPath('/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (3).jpg'), PosixPath('/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (1).jpg'), PosixPath('/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di 40_Santa_Maria_delle_Grazie.jpg'), PosixPath('/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di 1630611238845.jpg')]\n",
            "\n",
            "Verifica percorso video: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputVID\n",
            "Esiste? True\n",
            "È una directory? True\n",
            "Contenuto: [PosixPath('/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputVID/Copia di Copia di timelapse_chiostro.mov'), PosixPath('/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputVID/Copia di Copia di timelapse_chiostro_2.mp4')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNZIONI PER GOOGLE SHEETS (Opzionale)\n",
        "  #creds = None\n",
        "    # The file token.json stores the user's access and refresh tokens, and is\n",
        "    # created automatically when the authorization flow completes for the first\n",
        "    # time.\n",
        "    #if os.path.exists(os.path.abspath('token/token.json')):\n",
        "        #creds = Credentials.from_authorized_user_file(os.path.abspath('token/token.json'), SCOPES)\n",
        "    # If there are no (valid) credentials available, let the user log in.\n",
        "    #if not creds or not creds.valid:\n",
        "        #if creds and creds.expired and creds.refresh_token:\n",
        "            #creds.refresh(Request())\n",
        "        #else:\n",
        "            #flow = InstalledAppFlow.from_client_secrets_file(\n",
        "                #os.path.abspath('token/credentials.json'), SCOPES)\n",
        "            #creds = flow.run_local_server(port=0)\n",
        "        # Save the credentials for the next run\n",
        "        #with open(os.path.abspath('token/token.json'), 'w') as token:\n",
        "            #token.write(creds.to_json())\n",
        "   # return creds\n"
      ],
      "metadata": {
        "id": "q-EahwdZZ-BS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FUNZIONI PER GESTIONE LOG E FILE DI CONTROLLO\n",
        "def setup_logging(output_dir: Path):\n",
        "    \"\"\"Configura il logging sia su file che su console.\"\"\"\n",
        "    log_file = output_dir / \"run.log\"\n",
        "    # Rimuove handler esistenti per evitare log duplicati\n",
        "    for handler in logging.root.handlers[:]:\n",
        "        logging.root.removeHandler(handler)\n",
        "\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s %(levelname)s: %(message)s\",\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file),\n",
        "            logging.StreamHandler()\n",
        "        ]\n",
        "    )\n",
        "    logging.info(f\"Logging configurato. Log salvati in: {log_file}\")\n",
        "\n",
        "def is_already_processed(key: str) -> bool:\n",
        "    \"\"\"Controlla se una chiave è nel file processed.log.\"\"\"\n",
        "    try:\n",
        "        if not PROCESSED_LOG.exists():\n",
        "            return False\n",
        "        with open(PROCESSED_LOG, 'r') as f:\n",
        "           return any(key == line.strip() for line in f)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Errore leggendo {PROCESSED_LOG}: {e}\")\n",
        "        return False\n",
        "\n",
        "def mark_processed(key: str):\n",
        "    \"\"\"Aggiunge una chiave al file processed.log.\"\"\"\n",
        "    try:\n",
        "        with open(PROCESSED_LOG, \"a\") as f:\n",
        "            f.write(key + \"\\n\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Errore scrivendo su {PROCESSED_LOG}: {e}\")"
      ],
      "metadata": {
        "id": "0wTXilgwaCEd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNZIONI PER ESTRAZIONE FRAME E MODIFICA EXIF\n",
        "def extract_frames(video_path: Path, frame_output_base_dir: Path, interval_sec: int) -> list:\n",
        "    \"\"\"Estrae frame da un video, salvandoli in una sottocartella specifica.\"\"\"\n",
        "    saved_frames_paths = []\n",
        "    # Crea sottocartella specifica per i frame di questo video dentro la base dir\n",
        "    video_frame_dir = frame_output_base_dir / video_path.stem\n",
        "    video_frame_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(str(video_path))\n",
        "        if not cap.isOpened():\n",
        "            logging.error(f\"Impossibile aprire il video: {video_path}\")\n",
        "            return []\n",
        "\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "        if fps <= 0: fps = 30\n",
        "        step = max(1, int(fps * interval_sec)) # Assicura che step sia almeno 1\n",
        "\n",
        "        frame_count = 0\n",
        "        saved_frame_index = 0\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        pbar_desc = f\"Extracting frames from {video_path.name}\"\n",
        "        with tqdm(total=total_frames, desc=pbar_desc) as pbar:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret: break\n",
        "\n",
        "                if frame_count % step == 0:\n",
        "                    out_filename = f\"{video_path.stem}_frame{saved_frame_index:05d}.jpg\" # Padding aumentato\n",
        "                    out_file_path = video_frame_dir / out_filename\n",
        "                    success_write = cv2.imwrite(str(out_file_path), frame, [cv2.IMWRITE_JPEG_QUALITY, 90])\n",
        "                    if success_write:\n",
        "                        saved_frames_paths.append(out_file_path)\n",
        "                        saved_frame_index += 1\n",
        "                    else:\n",
        "                        logging.warning(f\"Errore nel salvataggio del frame: {out_file_path}\")\n",
        "\n",
        "                frame_count += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "        cap.release()\n",
        "        logging.info(f\"Estratti {len(saved_frames_paths)} frame da {video_path.name} in {video_frame_dir}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Errore durante estrazione frame da {video_path}: {e}\")\n",
        "        if 'cap' in locals() and cap.isOpened(): cap.release()\n",
        "        # Pulizia parziale in caso di errore?\n",
        "        # shutil.rmtree(video_frame_dir, ignore_errors=True) # Rimuove cartella anche se errore\n",
        "        return []\n",
        "\n",
        "    return saved_frames_paths\n",
        "\n",
        "def update_image_exif(img_path: Path, label: str):\n",
        "    \"\"\"Scrive etichetta nel campo EXIF ImageDescription.\"\"\"\n",
        "    if not img_path.is_file():\n",
        "        logging.warning(f\"Impossibile aggiornare EXIF, file non trovato: {img_path}\")\n",
        "        return\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        try:\n",
        "           exif_dict = piexif.load(img.info.get('exif', b\"\"))\n",
        "        except (piexif.InvalidImageDataError, ValueError) as exif_load_err:\n",
        "            logging.warning(f\"Dati EXIF non validi/assenti/corrotti in {img_path.name} ({exif_load_err}). Creazione nuovo dizionario.\")\n",
        "            exif_dict = {'0th': {}, 'Exif': {}, 'GPS': {}, '1st': {}, 'thumbnail': None}\n",
        "\n",
        "        if '0th' not in exif_dict: exif_dict['0th'] = {}\n",
        "\n",
        "        exif_dict['0th'][piexif.ImageIFD.ImageDescription] = label.encode('utf-8')\n",
        "\n",
        "        # Rimuove il thumbnail esistente per sicurezza\n",
        "        if 'thumbnail' in exif_dict: exif_dict['thumbnail'] = None\n",
        "\n",
        "        try:\n",
        "            exif_bytes = piexif.dump(exif_dict)\n",
        "        except Exception as dump_error:\n",
        "            logging.error(f\"Errore durante piexif.dump per {img_path.name}: {dump_error}\")\n",
        "            img.close()\n",
        "            return\n",
        "\n",
        "        try:\n",
        "           img_format = img.format # Preserva formato originale\n",
        "           img.save(img_path, exif=exif_bytes, format=img_format, quality=95) # Aggiunta quality\n",
        "           logging.debug(f\"EXIF aggiornato per: {img_path.name} con etichetta '{label}'\")\n",
        "        except Exception as save_error:\n",
        "            logging.error(f\"Errore durante salvataggio {img_path.name} con EXIF: {save_error}\")\n",
        "\n",
        "        img.close()\n",
        "\n",
        "    except FileNotFoundError:\n",
        "         logging.warning(f\"File non trovato durante tentativo aggiornamento EXIF: {img_path}\")\n",
        "    except UnidentifiedImageError:\n",
        "         logging.warning(f\"PIL non riconosce il formato immagine: {img_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Errore generico aggiornamento EXIF per {img_path}: {e}\")\n",
        "        if 'img' in locals() and hasattr(img, 'close'): img.close()"
      ],
      "metadata": {
        "id": "JVdeuANkaFjD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FUNZIONE PER CALCOLO NITIDEZZA\n",
        "def calculate_sharpness(image_cv2):\n",
        "    \"\"\"Calcola la varianza del Laplaciano per un'immagine OpenCV.\"\"\"\n",
        "    if image_cv2 is None or image_cv2.size == 0: return 0.0\n",
        "    try:\n",
        "        if image_cv2.ndim == 3: gray = cv2.cvtColor(image_cv2, cv2.COLOR_BGR2GRAY)\n",
        "        elif image_cv2.ndim == 2: gray = image_cv2\n",
        "        else: return 0.0\n",
        "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        return laplacian_var\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Errore in calculate_sharpness: {e}\")\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "WxaRFXqeaJxd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definizione e Preparazione Modello (TensorFlow/Keras)\n",
        "\n",
        "def build_model(num_classes: int) -> models.Model:\n",
        "    \"\"\"Costruisce un modello ResNet50 per fine-tuning.\"\"\"\n",
        "    backbone = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(*IMG_SIZE, 3))\n",
        "    x = layers.GlobalAveragePooling2D(name=\"gap\")(backbone.output)\n",
        "    x = layers.Dropout(0.5, name=\"dropout\")(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"predictions\")(x)\n",
        "    model = models.Model(backbone.input, outputs, name=\"resnet50_finetuned\")\n",
        "\n",
        "    logging.info(f\"Congelamento {len(backbone.layers)} layer del backbone ResNet50.\")\n",
        "    for layer in backbone.layers: layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=LEARN_HEAD_LR),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    logging.info(\"Modello compilato per training testa.\")\n",
        "    return model\n",
        "\n",
        "# Modifica la funzione make_dataset in questo modo:\n",
        "\n",
        "def make_dataset(dirpath: Path, shuffle: bool, subset: str = None, validation_split: float = None):\n",
        "    \"\"\"Crea un tf.data.Dataset da una directory, con opzione split,\n",
        "       e restituisce il dataset e i nomi delle classi.\"\"\"\n",
        "    if not dirpath.is_dir():\n",
        "        logging.error(f\"Directory dataset non trovata: {dirpath}\")\n",
        "        return None, None # Restituisce None per ds e class_names\n",
        "    try:\n",
        "        # Crea il dataset INIZIALE per ottenere class_names\n",
        "        initial_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            dirpath,\n",
        "            labels=\"inferred\",\n",
        "            label_mode=\"categorical\", # Importante per num_classes\n",
        "            batch_size=BATCH_SIZE,    # Il batch size qui non influenza class_names\n",
        "            image_size=IMG_SIZE,      # Nemmeno image_size\n",
        "            shuffle=shuffle,          # Shuffle qui non è cruciale per class_names\n",
        "            seed=123,\n",
        "            validation_split=validation_split,\n",
        "            subset=subset\n",
        "        )\n",
        "        if not initial_ds:\n",
        "           logging.error(f\"image_dataset_from_directory (initial) ha restituito None per {dirpath}\")\n",
        "           return None, None\n",
        "\n",
        "        class_names = initial_ds.class_names # Ottieni i nomi delle classi QUI\n",
        "        logging.info(f\"Dataset creato da {dirpath}. Classi trovate: {class_names}\")\n",
        "\n",
        "        # Ora puoi applicare map e prefetch come prima sull'initial_ds\n",
        "        # o ricreare il dataset se preferisci, ma usare initial_ds è efficiente\n",
        "        processed_ds = initial_ds.map(lambda imgs, labs: (preprocess_input(imgs), labs),\n",
        "                                       num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        processed_ds = processed_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "        return processed_ds, class_names # Restituisce entrambi\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Errore creazione dataset da {dirpath}: {e}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "KG1QCWpDaMKs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args):\n",
        "    \"\"\"Esegue il ciclo di training completo.\"\"\"\n",
        "    setup_logging(args.output) # Assicurati che setup_logging sia definita\n",
        "    logging.info(\"--- Inizio Processo di Training ---\")\n",
        "\n",
        "    # Gestione dataset training/validazione\n",
        "    validation_split_needed = 0.2\n",
        "    train_dir_path = Path(args.train_dir)\n",
        "    val_dir_path = Path(args.val_dir) if args.val_dir else None # Può essere stringa vuota o None\n",
        "\n",
        "    class_names_list = None # Inizializza per i nomi delle classi\n",
        "\n",
        "    if val_dir_path and val_dir_path.is_dir(): # Se val_dir è un percorso valido e una directory\n",
        "        logging.info(f\"Uso directory separata per validazione: {val_dir_path}\")\n",
        "        train_ds, class_names_list = make_dataset(train_dir_path, shuffle=True)\n",
        "        # Per val_ds, i class_names dovrebbero essere gli stessi, quindi non li riassegniamo\n",
        "        val_ds, _ = make_dataset(val_dir_path, shuffle=False)\n",
        "    else:\n",
        "        if val_dir_path: # Se era specificato ma non valido\n",
        "             logging.warning(f\"Directory di validazione '{val_dir_path}' non trovata o non valida.\")\n",
        "        logging.info(f\"Uso {validation_split_needed*100}% split da {train_dir_path} per validazione.\")\n",
        "        train_ds, class_names_list = make_dataset(train_dir_path, shuffle=True, subset='training', validation_split=validation_split_needed)\n",
        "        val_ds, _ = make_dataset(train_dir_path, shuffle=False, subset='validation', validation_split=validation_split_needed)\n",
        "\n",
        "    # Controlla se i dataset e i nomi delle classi sono stati creati correttamente\n",
        "    if train_ds is None or val_ds is None or class_names_list is None:\n",
        "         logging.error(\"Creazione dataset o recupero nomi classi fallita. Training interrotto.\")\n",
        "         return\n",
        "\n",
        "    num_classes = len(class_names_list)\n",
        "    logging.info(f\"Numero classi: {num_classes} - Nomi: {class_names_list}\")\n",
        "    if num_classes < 2:\n",
        "        logging.error(\"Richieste almeno 2 classi per il training. Training interrotto.\")\n",
        "        return\n",
        "\n",
        "    # Costruzione modello\n",
        "    # Assicurati che build_model sia definita e usi le costanti globali corrette\n",
        "    model = build_model(num_classes)\n",
        "\n",
        "    # Callback\n",
        "    checkpoint_head_path = args.output / \"model_head_best.h5\"\n",
        "    checkpoint_fine_path = args.output / \"model_fine_tuned_best.h5\"\n",
        "\n",
        "    # Salva solo i pesi se vuoi più flessibilità nel ricostruire il modello,\n",
        "    # altrimenti save_weights_only=False salva l'intero modello (architettura + pesi + stato optimizer)\n",
        "    model_checkpoint_head = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=str(checkpoint_head_path), # Keras preferisce stringhe per i percorsi\n",
        "        save_weights_only=False,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "    )\n",
        "    model_checkpoint_fine = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=str(checkpoint_fine_path),\n",
        "        save_weights_only=False,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True\n",
        "    )\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5, # Numero di epoche senza miglioramenti prima di fermarsi\n",
        "        restore_best_weights=True # Ripristina i pesi dell'epoca con la miglior val_loss\n",
        "    )\n",
        "\n",
        "    # Training testa\n",
        "    logging.info(f\"--- Training testa per {args.epochs_head} epoche (LR={args.learn_head_lr}) ---\")\n",
        "    # Assicurati che args.epochs_head e args.learn_head_lr siano accessibili e corretti\n",
        "    model.fit(train_ds, validation_data=val_ds, epochs=args.epochs_head, callbacks=[model_checkpoint_head])\n",
        "    logging.info(\"Training testa completato.\")\n",
        "\n",
        "    # Carica pesi migliori testa (se il modello è stato salvato interamente, questo ricarica il miglior modello)\n",
        "    if checkpoint_head_path.exists():\n",
        "        logging.info(f\"Caricamento del miglior modello dal training della testa da {checkpoint_head_path}\")\n",
        "        model = models.load_model(checkpoint_head_path) # Carica l'intero modello, non solo i pesi\n",
        "    else:\n",
        "        logging.warning(\"Checkpoint del training testa non trovato. Si procede con gli ultimi pesi del modello attuale.\")\n",
        "\n",
        "    # Sblocco layer per fine-tuning\n",
        "    logging.info(\"--- Fine-tuning completo: Sblocco layer ---\")\n",
        "    # Esempio: sblocca tutti i layer del backbone.\n",
        "    # si potrebbe voler sbloccare solo una parte per fine-tuning più conservativo.\n",
        "    # In genere, i layer di BatchNormalization si tengono congelati quando si fa fine-tuning\n",
        "    # se il backbone è stato pre-allenato con essi.\n",
        "    for layer in model.layers: # Itera su tutti i layer, incluso il backbone\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "        # Se si vogliono sbloccare anche i layer di Batch Normalization del backbone:\n",
        "        # else:\n",
        "        # layer.trainable = True # Attenzione: può destabilizzare se il batch size è piccolo\n",
        "\n",
        "    # In alternativa, un modo comune è sbloccare i layer del backbone originale\n",
        "    # if hasattr(model, 'get_layer') and model.get_layer(name='resnet50'): # Assumendo che il backbone si chiami 'resnet50'\n",
        "    #    backbone = model.get_layer(name='resnet50') # Ottieni il backbone\n",
        "    #    # Sblocca gli ultimi N blocchi del backbone, ad esempio\n",
        "    #    fine_tune_at = 100 # Numero di layer da sbloccare dalla fine\n",
        "    #    for layer in backbone.layers[-fine_tune_at:]:\n",
        "    #        if not isinstance(layer, layers.BatchNormalization):\n",
        "    #            layer.trainable = True\n",
        "\n",
        "    logging.info(f\"Layer trainabili dopo sblocco: {sum(1 for l in model.layers if l.trainable)}\")\n",
        "\n",
        "    # Ricompilare con LR basso\n",
        "    # Assicurarsi che args.learn_full_lr sia accessibile e corretto\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=args.learn_full_lr),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    logging.info(f\"Modello ricompilato per fine-tuning (LR={args.learn_full_lr})\")\n",
        "\n",
        "    # Fine-tuning\n",
        "    # Assicurarsi che args.epochs_fine sia accessibile e corretto\n",
        "    logging.info(f\"--- Fine-tuning per max {args.epochs_fine} epoche (LR={args.learn_full_lr}) ---\")\n",
        "    model.fit(train_ds, validation_data=val_ds, epochs=args.epochs_fine, callbacks=[model_checkpoint_fine, early_stopping])\n",
        "    logging.info(\"Fine-tuning completato.\")\n",
        "\n",
        "    # Salvataggio modello finale\n",
        "    final_model_path = args.output / \"place_model.h5\"\n",
        "    # Se early_stopping ha ripristinato i pesi migliori e model_checkpoint_fine ha salvato\n",
        "    # il modello in quell'epoca, allora checkpoint_fine_path è il migliore.\n",
        "    # Altrimenti, se early_stopping non è scattato ma save_best_only sì,\n",
        "    # checkpoint_fine_path è comunque il migliore di quel run.\n",
        "    # Se nessun checkpoint è stato salvato (es. solo 1 epoca e non abbastanza buona),\n",
        "    # allora salviamo lo stato attuale del modello.\n",
        "    if checkpoint_fine_path.exists():\n",
        "        logging.info(f\"Salvataggio del miglior modello dal fine-tuning ({checkpoint_fine_path}) come modello finale.\")\n",
        "        # Se checkpoint_fine_path è stato salvato, dovrebbe essere il modello migliore o l'ultimo.\n",
        "        # Rinominiamo per chiarezza se è il migliore, altrimenti si salva l'ultimo stato del modello.\n",
        "        # Poiché early_stopping ha restore_best_weights=True, model CONTIENE GIÀ i pesi migliori\n",
        "        # al termine di model.fit se early stopping è scattato.\n",
        "        # Quindi, possiamo semplicemente salvare 'model'.\n",
        "        # ModelCheckpoint con save_best_only=True potrebbe aver già salvato il migliore in checkpoint_fine_path.\n",
        "        # Se early_stopping ha ripristinato i pesi e model_checkpoint_fine non ha salvato *quella precisa* epoca,\n",
        "        # allora model è meglio di checkpoint_fine_path.\n",
        "        # La logica più sicura è: se EarlyStopping ha funzionato, 'model' ha i pesi migliori.\n",
        "        # Se ModelCheckpoint ha salvato qualcosa, potrebbe essere l'ultima migliore epoca.\n",
        "        # Priorità a EarlyStopping se ha ripristinato.\n",
        "        if early_stopping.stopped_epoch > 0 and early_stopping.restore_best_weights:\n",
        "            logging.info(\"Early stopping ha ripristinato i pesi migliori. Salvataggio dello stato corrente del modello.\")\n",
        "            model.save(final_model_path)\n",
        "        elif checkpoint_fine_path.exists():\n",
        "            logging.info(f\"Uso del checkpoint salvato da ModelCheckpoint: {checkpoint_fine_path}\")\n",
        "            checkpoint_fine_path.rename(final_model_path)\n",
        "        else:\n",
        "            logging.warning(\"Nessun checkpoint di fine-tuning salvato e EarlyStopping non ha ripristinato pesi. Salvataggio dello stato attuale del modello.\")\n",
        "            model.save(final_model_path)\n",
        "    else: # Se il file di checkpoint non esiste affatto\n",
        "        logging.info(\"Nessun checkpoint di fine-tuning trovato. Salvataggio dello stato attuale del modello.\")\n",
        "        model.save(final_model_path)\n",
        "\n",
        "    logging.info(f\"Modello finale salvato in: {final_model_path}\")\n",
        "\n",
        "    # Salvataggio mappatura classi usando class_names_list\n",
        "    class_indices_path = args.output / \"class_indices.csv\"\n",
        "    try:\n",
        "        pd.DataFrame({\"class_name\": class_names_list, \"index\": list(range(num_classes))}).to_csv(class_indices_path, index=False)\n",
        "        logging.info(f\"Mappatura classi salvata in: {class_indices_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Errore durante il salvataggio della mappatura classi: {e}\")\n",
        "\n",
        "    logging.info(\"--- Processo di Training Concluso ---\")"
      ],
      "metadata": {
        "id": "TrwJDsVFaRjP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione di Inferenza (Corretta)\n",
        "\n",
        "def infer(args):\n",
        "    \"\"\"Esegue inferenza su immagini e video.\"\"\"\n",
        "    setup_logging(args.output)\n",
        "    logging.info(\"--- Inizio Processo di Inferenza ---\")\n",
        "\n",
        "    # Caricamento modello e classi\n",
        "    model_path = args.output / \"place_model.h5\"\n",
        "    class_indices_path = args.output / \"class_indices.csv\"\n",
        "    if not model_path.exists() or not class_indices_path.exists():\n",
        "        logging.error(f\"Modello ({model_path}) o indici classi ({class_indices_path}) non trovati.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        model = models.load_model(model_path)\n",
        "        logging.info(f\"Modello caricato da {model_path}\")\n",
        "        idx_df = pd.read_csv(class_indices_path)\n",
        "        class_names = idx_df.sort_values(\"index\")[\"class_name\"].tolist()\n",
        "        logging.info(f\"Classi caricate: {class_names}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Errore caricamento modello o classi: {e}\")\n",
        "        return\n",
        "\n",
        "         #Preparazione file CSV output\n",
        "    csv_fieldnames = [\"SourceType\", \"PredictedPlace\", \"OriginalPath\", \"Confidence\", \"IsVideo\", \"BestFrameSavedPath\", \"Sharpness\"]\n",
        "    try:\n",
        "        csv_file = open(args.csv_path, \"a\", newline=\"\", encoding='utf-8')\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=csv_fieldnames)\n",
        "        if csv_file.tell() == 0: # Scrive header se file è vuoto\n",
        "            writer.writeheader()\n",
        "        logging.info(f\"File CSV pronto: {args.csv_path}\")\n",
        "    except Exception as e:\n",
        "         logging.error(f\"Impossibile aprire/scrivere file CSV {args.csv_path}: {e}\")\n",
        "         return\n",
        "\n",
        "    # Funzione Helper per caricare/preprocessare immagine per inferenza\n",
        "    # TENERE SOLO QUESTA DEFINIZIONE\n",
        "    def load_and_preprocess_img_infer(path_str: str):\n",
        "        # logging.debug(f\"Tentativo caricamento frame: {path_str}\")\n",
        "        try:\n",
        "            img_bytes = tf.io.read_file(path_str)\n",
        "            # logging.debug(f\"  --> Letto {len(img_bytes)} bytes da {path_str}\")\n",
        "            img = tf.image.decode_jpeg(img_bytes, channels=3)\n",
        "            # logging.debug(f\"  --> Decodificato frame {path_str}, shape: {img.shape}\")\n",
        "            img = tf.image.resize(img, IMG_SIZE)\n",
        "            # logging.debug(f\"  --> Ridimensionato frame {path_str}\")\n",
        "            img = preprocess_input(img)\n",
        "            # logging.debug(f\"  --> Preprocessato frame {path_str}\")\n",
        "            return img\n",
        "        except tf.errors.InvalidArgumentError as e:\n",
        "             logging.error(f\"TF ArgumentError per {path_str}: {e}\")\n",
        "             return None\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Errore generico caricamento/prep immagine {path_str}: {e}\")\n",
        "            return None\n",
        "\n",
        "    # INFERENZA IMMAGINI SINGOLE\n",
        "    logging.info(f\"Inferenza immagini in: {args.img_dir}\")\n",
        "    img_dir = Path(args.img_dir)\n",
        "    if not img_dir.is_dir():\n",
        "         logging.warning(f\"Directory immagini input non trovata: {img_dir}\")\n",
        "    else:\n",
        "        img_files = sorted(list(img_dir.glob(\"*.jpg\")) + list(img_dir.glob(\"*.png\")) + list(img_dir.glob(\"*.jpeg\")))\n",
        "        logging.info(f\"Trovate {len(img_files)} immagini.\")\n",
        "\n",
        "        valid_img_paths_str = []\n",
        "        original_img_paths = []\n",
        "\n",
        "        print(\"\\nDEBUG: Inizio ciclo filtro immagini...\")\n",
        "        for i, p in enumerate(img_files): # NUOVO CICLO CON DEBUG\n",
        "            key = f\"IMG::{p.resolve()}\"\n",
        "            print(f\"DEBUG {i+1}/{len(img_files)}: Processando '{p.name}' - Key: '{key}'\")\n",
        "\n",
        "            already_processed = is_already_processed(key)\n",
        "            print(f\"DEBUG {i+1}: Risultato is_already_processed: {already_processed}\")\n",
        "            if already_processed:\n",
        "                print(f\"DEBUG {i+1}: Immagine saltata perché già processata.\")\n",
        "                continue\n",
        "\n",
        "            print(f\"DEBUG {i+1}: Tentativo tf.io.read_file...\")\n",
        "            try:\n",
        "                tf_read_success = False\n",
        "                _ = tf.io.read_file(str(p))\n",
        "                tf_read_success = True\n",
        "                print(f\"DEBUG {i+1}: tf.io.read_file OK.\")\n",
        "                valid_img_paths_str.append(str(p))\n",
        "                original_img_paths.append(p)\n",
        "                print(f\"DEBUG {i+1}: Aggiunta alle liste valide.\")\n",
        "            except Exception as e:\n",
        "                print(f\"DEBUG {i+1}: Eccezione durante tf.io.read_file: {e}\")\n",
        "                logging.warning(f\"Immagine corrotta/non leggibile (saltata): {p.name} ({e})\")\n",
        "\n",
        "        # Controllo finale liste e continuazione\n",
        "        print(f\"\\nDEBUG: Fine ciclo filtro immagini.\")\n",
        "        print(f\"DEBUG: Lunghezza valid_img_paths_str: {len(valid_img_paths_str)}\")\n",
        "        print(f\"DEBUG: Lunghezza original_img_paths: {len(original_img_paths)}\")\n",
        "\n",
        "        if valid_img_paths_str:\n",
        "            print(\"DEBUG: Entrando nel blocco 'if valid_img_paths_str:'. Inizio creazione dataset immagini.\")\n",
        "            img_dataset = tf.data.Dataset.from_tensor_slices(valid_img_paths_str)\n",
        "            img_dataset = img_dataset.map(load_and_preprocess_img_infer, num_parallel_calls=tf.data.AUTOTUNE).filter(lambda x: x is not None)\n",
        "            img_dataset = img_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "            logging.info(f\"Predizioni su {len(original_img_paths)} nuove immagini valide...\")\n",
        "            all_predictions = model.predict(img_dataset)\n",
        "\n",
        "            # Ciclo per processare le predizioni (con i debug print che hai già inserito)\n",
        "            print(\"DEBUG: Inizio ciclo processamento predizioni immagini...\") # Aggiunto per chiarezza\n",
        "            for i, pred in enumerate(all_predictions):\n",
        "                print(f\"\\nDEBUG Immagine {i}: {original_img_paths[i].name}\")\n",
        "                print(f\"DEBUG: Predizione grezza (pred): {pred}\")\n",
        "                print(f\"DEBUG: Tipo di pred: {type(pred)}\")\n",
        "                print(f\"DEBUG: Shape di pred: {pred.shape}\")\n",
        "\n",
        "                label_idx = np.argmax(pred)\n",
        "                raw_confidence = pred[label_idx]\n",
        "                print(f\"DEBUG: Valore confidenza grezza (pred[label_idx]): {raw_confidence}\") # Già aggiunto\n",
        "                confidence = float(raw_confidence)\n",
        "                label = class_names[label_idx]\n",
        "\n",
        "                print(f\"DEBUG: Indice={label_idx}, Confidenza calcolata={confidence}, Etichetta={label}\") # Già aggiunto\n",
        "\n",
        "                img_path = original_img_paths[i]\n",
        "                key = f\"IMG::{img_path.resolve()}\"\n",
        "\n",
        "                logging.info(f\"Img: {img_path.name} -> Classe: {label} (Conf: {confidence:.3f})\")\n",
        "\n",
        "                csv_row = {\n",
        "                    \"SourceType\": \"Image\", \"PredictedPlace\": label,\n",
        "                    \"OriginalPath\": str(img_path.resolve()), \"Confidence\": f\"{confidence:.4f}\",\n",
        "                    \"IsVideo\": 0, \"BestFrameSavedPath\": \"N/A\", \"Sharpness\": \"N/A\"\n",
        "                }\n",
        "                writer.writerow(csv_row)\n",
        "\n",
        "                update_image_exif(img_path, label)\n",
        "                mark_processed(key)\n",
        "            print(\"DEBUG: Fine ciclo processamento predizioni immagini.\") # Aggiunto per chiarezza\n",
        "\n",
        "            logging.info(f\"Completata inferenza su {len(original_img_paths)} immagini.\")\n",
        "        else:\n",
        "             print(\"DEBUG: Entrando nel blocco 'else'. Nessuna nuova immagine valida trovata.\")\n",
        "             logging.info(\"Nessuna nuova immagine valida trovata.\")\n",
        "\n",
        "              # INFERENZA VIDEO\n",
        "    logging.info(f\"Inferenza video in: {args.vid_dir}\")\n",
        "    vid_dir = Path(args.vid_dir)\n",
        "    if not vid_dir.is_dir():\n",
        "         logging.warning(f\"Directory video input non trovata: {vid_dir}\")\n",
        "    else:\n",
        "        video_files = sorted(list(vid_dir.glob(\"*.mp4\")) + list(vid_dir.glob(\"*.mov\")) + list(vid_dir.glob(\"*.avi\")))\n",
        "        logging.info(f\"Trovati {len(video_files)} video.\")\n",
        "\n",
        "        for vid_path in video_files:\n",
        "            key = f\"VID::{vid_path.resolve()}\"\n",
        "            if is_already_processed(key):\n",
        "                logging.info(f\"Video già processato (saltato): {vid_path.name}\")\n",
        "                continue\n",
        "\n",
        "            logging.info(f\"Processando video: {vid_path.name}\")\n",
        "            current_video_temp_frame_dir = TEMP_FRAME_EXTRACT_DIR / vid_path.stem\n",
        "\n",
        "             # 1. Estrazione Frame\n",
        "            frame_paths = extract_frames(vid_path, TEMP_FRAME_EXTRACT_DIR, args.frame_interval)\n",
        "            if not frame_paths:\n",
        "                logging.warning(f\"Errore o nessun frame estratto da {vid_path.name}. Salto.\")\n",
        "                continue\n",
        "\n",
        "                 # 2. Predizione sui frame\n",
        "            frame_paths_str = [str(p) for p in frame_paths]\n",
        "            if not frame_paths_str: # Doppia verifica\n",
        "                 logging.warning(f\"Lista path frame vuota per {vid_path.name}. Salto.\")\n",
        "                 continue\n",
        "\n",
        "            frame_dataset = tf.data.Dataset.from_tensor_slices(frame_paths_str)\n",
        "            frame_dataset = frame_dataset.map(load_and_preprocess_img_infer, num_parallel_calls=tf.data.AUTOTUNE).filter(lambda x: x is not None)\n",
        "            # Ricalcola numero effettivo di frame validi\n",
        "            valid_frame_count = tf.data.experimental.cardinality(frame_dataset).numpy()\n",
        "            if valid_frame_count <= 0:\n",
        "                logging.warning(f\"Nessun frame valido dopo preprocessing per {vid_path.name}. Salto.\")\n",
        "                shutil.rmtree(current_video_temp_frame_dir, ignore_errors=True) # Pulisci\n",
        "                continue\n",
        "\n",
        "            frame_dataset = frame_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "            logging.info(f\"Predizioni su {valid_frame_count} frame validi...\")\n",
        "\n",
        "            try:\n",
        "                all_predictions = model.predict(frame_dataset)\n",
        "                if all_predictions.shape[0] != valid_frame_count:\n",
        "                    logging.warning(f\"Numero predizioni ({all_predictions.shape[0]}) non corrisponde ai frame validi ({valid_frame_count}) per {vid_path.name}. Potrebbero esserci stati errori nel map.\")\n",
        "                    # Potresti voler interrompere qui o procedere con cautela\n",
        "                all_pred_indices = np.argmax(all_predictions, axis=1)\n",
        "                all_pred_confidences = np.max(all_predictions, axis=1)\n",
        "            except Exception as pred_err:\n",
        "                 logging.error(f\"Errore predizione frame {vid_path.name}: {pred_err}\")\n",
        "                 shutil.rmtree(current_video_temp_frame_dir, ignore_errors=True) # Pulisci\n",
        "                 continue\n",
        "                  # 3. Determina Classe Dominante\n",
        "            if len(all_pred_indices) == 0:\n",
        "                 logging.warning(f\"Nessuna predizione valida per {vid_path.name}. Salto.\")\n",
        "                 shutil.rmtree(current_video_temp_frame_dir, ignore_errors=True) # Pulisci\n",
        "                 continue\n",
        "\n",
        "            majority_idx = np.bincount(all_pred_indices).argmax()\n",
        "            video_label = class_names[majority_idx]\n",
        "            majority_confidences = all_pred_confidences[all_pred_indices == majority_idx]\n",
        "            video_confidence = float(np.mean(majority_confidences)) if len(majority_confidences) > 0 else 0.0\n",
        "            logging.info(f\"Video: {vid_path.name} -> Classe: {video_label} (Conf. media: {video_confidence:.3f})\")\n",
        "\n",
        "              # 4. Seleziona Frame Migliori\n",
        "            candidate_frames_info = []\n",
        "            # Associa predizioni ai path originali (potrebbe essere imperfetto se filter() ha rimosso frame)\n",
        "            # Un modo più robusto sarebbe fare `predict` su ogni frame singolarmente, ma più lento.\n",
        "            # Tentativo di associazione basato sull'ordine (funziona se filter non rimuove nulla)\n",
        "            if len(frame_paths) == len(all_pred_indices):\n",
        "                for i, frame_path in enumerate(frame_paths):\n",
        "                    if all_pred_indices[i] == majority_idx:\n",
        "                        try:\n",
        "                            frame_img_cv2 = cv2.imread(str(frame_path))\n",
        "                            if frame_img_cv2 is None: continue\n",
        "                            sharpness = calculate_sharpness(frame_img_cv2)\n",
        "                            if sharpness >= args.sharpness_threshold:\n",
        "                                candidate_frames_info.append((sharpness, frame_path, all_pred_confidences[i]))\n",
        "                        except Exception as e:\n",
        "                             logging.error(f\"Errore analisi nitidezza frame {frame_path}: {e}\")\n",
        "            else:\n",
        "                 logging.warning(f\"Numero predizioni non corrisponde a numero frame estratti per {vid_path.name}. Selezione frame migliori potrebbe essere imprecisa.\")\n",
        "                 # Fallback: analizza tutti i frame estratti individualmente se necessario (più lento)\n",
        "\n",
        "\n",
        "            candidate_frames_info.sort(key=lambda x: x[0], reverse=True) # Ordina per nitidezza\n",
        "            best_frames_to_save = candidate_frames_info[:args.frames_per_place]\n",
        "            logging.info(f\"Selezionati {len(best_frames_to_save)} frame candidati (sharp >= {args.sharpness_threshold}).\")\n",
        "\n",
        "            # 5. Salva Frame Migliori e Aggiorna EXIF\n",
        "            saved_best_frame_paths = []\n",
        "            if best_frames_to_save:\n",
        "                video_best_frames_dir = BEST_FRAMES_OUTPUT_DIR / video_label / vid_path.stem\n",
        "                video_best_frames_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                for sharpness, frame_path, frame_conf in best_frames_to_save:\n",
        "                    frame_index_str = Path(frame_path).stem.split('frame')[-1] # Estrae numero frame\n",
        "                    out_filename = f\"{vid_path.stem}__{video_label}__frame{frame_index_str}_sharp{sharpness:.0f}_conf{frame_conf:.3f}.jpg\"\n",
        "                    out_path = video_best_frames_dir / out_filename\n",
        "                    try:\n",
        "                        shutil.copy(frame_path, out_path) # Copia il frame\n",
        "                        update_image_exif(out_path, video_label) # Aggiorna EXIF della copia\n",
        "                        saved_best_frame_paths.append(str(out_path.resolve()))\n",
        "                    except Exception as e:\n",
        "                        logging.error(f\"Errore salvataggio/EXIF frame migliore {out_path}: {e}\")\n",
        "\n",
        "            # 6. Scrittura CSV\n",
        "            csv_row = {\n",
        "                \"SourceType\": \"Video\", \"PredictedPlace\": video_label,\n",
        "                \"OriginalPath\": str(vid_path.resolve()), \"Confidence\": f\"{video_confidence:.4f}\",\n",
        "                \"IsVideo\": 1,\n",
        "                \"BestFrameSavedPath\": \";\".join(saved_best_frame_paths) if saved_best_frame_paths else \"N/A\",\n",
        "                \"Sharpness\": f\"{best_frames_to_save[0][0]:.1f}\" if best_frames_to_save else \"N/A\"\n",
        "            }\n",
        "            writer.writerow(csv_row)\n",
        "\n",
        "              # 7. Aggiorna Sheets (Opzionale)\n",
        "            # if creds:\n",
        "            #     sheet_row = [\"Video\", video_label, str(vid_path.resolve()), pd.Timestamp.now().isoformat()]\n",
        "            #     append_row_to_sheet(creds, args.spreadsheet_id, args.sheet_name, sheet_row)\n",
        "\n",
        "            # 8. Marca video come processato\n",
        "            mark_processed(key)\n",
        "\n",
        "            # 9. Pulizia frame temporanei\n",
        "            logging.info(f\"Pulizia frame temporanei per {vid_path.name}...\")\n",
        "            shutil.rmtree(current_video_temp_frame_dir, ignore_errors=True)\n",
        "\n",
        "    #Fine Ciclo Video\n",
        "    logging.info(\"Inferenza Video Completata\")\n",
        "\n",
        "    # Chiusura file CSV\n",
        "    try: csv_file.close()\n",
        "    except Exception as e: logging.error(f\"Errore chiusura CSV: {e}\")\n",
        "\n",
        "    logging.info(\"Processo di Inferenza Concluso\")\n"
      ],
      "metadata": {
        "id": "K3dVtlL_anCQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Google Sheets (Opzionale)\n",
        "    # creds = None\n",
        "    # service_account_path = GDRIVE_PROJECT_PATH / 'service_account.json'\n",
        "    # if args.spreadsheet_id and GOOGLE_LIBS_AVAILABLE:\n",
        "    #     logging.info(\"Configurazione Google Sheets...\")\n",
        "    #     creds = getCredentials(service_account_path)\n",
        "    #     if creds:\n",
        "    #         # ... (eventuale scrittura header e validazione dati) ...\n",
        "    #         logging.info(\"Google Sheets configurato.\")\n",
        "    #     else:\n",
        "    #         logging.warning(\"Credenziali Sheets non caricate. Integrazione disabilitata.\")\n",
        "    # else:\n",
        "    #      logging.info(\"Spreadsheet ID non fornito o librerie Google mancanti. Integrazione Sheets disabilitata.\")"
      ],
      "metadata": {
        "id": "s4hsuuVRa2Yd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Blocco Principale (Esecuzione Train o Infer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #Configurazione Manuale Argomenti\n",
        "    # Utile per esecuzione diretta in notebook/IDE\n",
        "    class Args: pass\n",
        "    args = Args()\n",
        "\n",
        "    #IMPOSTA LA MODALITÀ: 'train' o 'infer'\n",
        "    args.mode = \"infer\"\n",
        "\n",
        "    # Percorsi (derivati da GDRIVE_PROJECT_PATH)\n",
        "    args.train_dir = str(DEFAULT_TRAIN_DIR)\n",
        "    args.val_dir = str(DEFAULT_VAL_DIR) # Se non esiste, train() usa split\n",
        "    args.img_dir = str(DEFAULT_IMG_DIR)\n",
        "    args.vid_dir = str(DEFAULT_VID_DIR)\n",
        "    args.output = DEFAULT_OUTPUT\n",
        "    args.csv_path = DEFAULT_CSV\n",
        "\n",
        "    # Parametri training/inferenza\n",
        "    args.epochs_head = EPOCHS_HEAD\n",
        "    args.epochs_fine = EPOCHS_FINE\n",
        "    args.learn_head_lr = LEARN_HEAD_LR\n",
        "    args.learn_full_lr = LEARN_FULL_LR\n",
        "    args.frame_interval = FRAME_INTERVAL\n",
        "    args.sharpness_threshold = SHARPNESS_THRESHOLD\n",
        "    args.frames_per_place = FRAMES_PER_PLACE_PER_VIDEO\n",
        "\n",
        "    # Parametri Google Sheets (Opzionale)\n",
        "    args.spreadsheet_id = None # Es: \"YOUR_SPREADSHEET_ID\"\n",
        "    args.sheet_name = \"RisultatiInferenza\" # Nome foglio\n",
        "\n",
        "    #Esecuzione\n",
        "    if args.mode == \"train\":\n",
        "        train(args)\n",
        "    elif args.mode == \"infer\":\n",
        "        infer(args)\n",
        "    else:\n",
        "        print(f\"Errore: Modalità '{args.mode}' non riconosciuta.\")\n",
        "\n",
        "    print(\"\\nEsecuzione Blocco Principale Terminata\")"
      ],
      "metadata": {
        "id": "3p2eit6TbFxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b854d17-c1a5-4383-dbbd-66421396972a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:45:51,906 INFO: Logging configurato. Log salvati in: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/run.log\n",
            "2025-05-09 07:45:52,717 INFO: --- Inizio Processo di Inferenza ---\n",
            "2025-05-09 07:45:58,847 WARNING: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2025-05-09 07:46:01,288 INFO: Modello caricato da /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/place_model.h5\n",
            "2025-05-09 07:46:02,451 INFO: Classi caricate: ['chiostro_esterno', 'ingegneria_esterno']\n",
            "2025-05-09 07:46:02,455 INFO: File CSV pronto: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/results.csv\n",
            "2025-05-09 07:46:02,456 INFO: Inferenza immagini in: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG\n",
            "2025-05-09 07:46:02,461 INFO: Trovate 5 immagini.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DEBUG: Inizio ciclo filtro immagini...\n",
            "DEBUG 1/5: Processando 'Copia di 1630611238845.jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di 1630611238845.jpg'\n",
            "DEBUG 1: Risultato is_already_processed: False\n",
            "DEBUG 1: Tentativo tf.io.read_file...\n",
            "DEBUG 1: tf.io.read_file OK.\n",
            "DEBUG 1: Aggiunta alle liste valide.\n",
            "DEBUG 2/5: Processando 'Copia di 40_Santa_Maria_delle_Grazie.jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di 40_Santa_Maria_delle_Grazie.jpg'\n",
            "DEBUG 2: Risultato is_already_processed: False\n",
            "DEBUG 2: Tentativo tf.io.read_file...\n",
            "DEBUG 2: tf.io.read_file OK.\n",
            "DEBUG 2: Aggiunta alle liste valide.\n",
            "DEBUG 3/5: Processando 'Copia di download (1).jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (1).jpg'\n",
            "DEBUG 3: Risultato is_already_processed: False\n",
            "DEBUG 3: Tentativo tf.io.read_file...\n",
            "DEBUG 3: tf.io.read_file OK.\n",
            "DEBUG 3: Aggiunta alle liste valide.\n",
            "DEBUG 4/5: Processando 'Copia di download (2).jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (2).jpg'\n",
            "DEBUG 4: Risultato is_already_processed: False\n",
            "DEBUG 4: Tentativo tf.io.read_file...\n",
            "DEBUG 4: tf.io.read_file OK.\n",
            "DEBUG 4: Aggiunta alle liste valide.\n",
            "DEBUG 5/5: Processando 'Copia di download (3).jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (3).jpg'\n",
            "DEBUG 5: Risultato is_already_processed: False\n",
            "DEBUG 5: Tentativo tf.io.read_file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:46:07,994 INFO: Predizioni su 5 nuove immagini valide...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG 5: tf.io.read_file OK.\n",
            "DEBUG 5: Aggiunta alle liste valide.\n",
            "\n",
            "DEBUG: Fine ciclo filtro immagini.\n",
            "DEBUG: Lunghezza valid_img_paths_str: 5\n",
            "DEBUG: Lunghezza original_img_paths: 5\n",
            "DEBUG: Entrando nel blocco 'if valid_img_paths_str:'. Inizio creazione dataset immagini.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n",
            "2025-05-09 07:46:14,529 INFO: Img: Copia di 1630611238845.jpg -> Classe: ingegneria_esterno (Conf: 1.000)\n",
            "2025-05-09 07:46:14,572 WARNING: File non trovato durante tentativo aggiornamento EXIF: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di 1630611238845.jpg\n",
            "2025-05-09 07:46:14,580 INFO: Img: Copia di 40_Santa_Maria_delle_Grazie.jpg -> Classe: ingegneria_esterno (Conf: 1.000)\n",
            "2025-05-09 07:46:14,584 WARNING: File non trovato durante tentativo aggiornamento EXIF: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di 40_Santa_Maria_delle_Grazie.jpg\n",
            "2025-05-09 07:46:14,590 INFO: Img: Copia di download (1).jpg -> Classe: ingegneria_esterno (Conf: 1.000)\n",
            "2025-05-09 07:46:14,594 WARNING: File non trovato durante tentativo aggiornamento EXIF: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (1).jpg\n",
            "2025-05-09 07:46:14,600 INFO: Img: Copia di download (2).jpg -> Classe: ingegneria_esterno (Conf: 1.000)\n",
            "2025-05-09 07:46:14,603 WARNING: File non trovato durante tentativo aggiornamento EXIF: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (2).jpg\n",
            "2025-05-09 07:46:14,609 INFO: Img: Copia di download (3).jpg -> Classe: ingegneria_esterno (Conf: 1.000)\n",
            "2025-05-09 07:46:14,612 WARNING: File non trovato durante tentativo aggiornamento EXIF: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (3).jpg\n",
            "2025-05-09 07:46:14,616 INFO: Completata inferenza su 5 immagini.\n",
            "2025-05-09 07:46:14,617 INFO: Inferenza video in: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputVID\n",
            "2025-05-09 07:46:14,621 INFO: Trovati 2 video.\n",
            "2025-05-09 07:46:14,625 INFO: Processando video: Copia di Copia di timelapse_chiostro.mov\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG: Inizio ciclo processamento predizioni immagini...\n",
            "\n",
            "DEBUG Immagine 0: Copia di 1630611238845.jpg\n",
            "DEBUG: Predizione grezza (pred): [1.4702787e-04 9.9985290e-01]\n",
            "DEBUG: Tipo di pred: <class 'numpy.ndarray'>\n",
            "DEBUG: Shape di pred: (2,)\n",
            "DEBUG: Valore confidenza grezza (pred[label_idx]): 0.9998528957366943\n",
            "DEBUG: Indice=1, Confidenza calcolata=0.9998528957366943, Etichetta=ingegneria_esterno\n",
            "\n",
            "DEBUG Immagine 1: Copia di 40_Santa_Maria_delle_Grazie.jpg\n",
            "DEBUG: Predizione grezza (pred): [3.5119410e-05 9.9996483e-01]\n",
            "DEBUG: Tipo di pred: <class 'numpy.ndarray'>\n",
            "DEBUG: Shape di pred: (2,)\n",
            "DEBUG: Valore confidenza grezza (pred[label_idx]): 0.9999648332595825\n",
            "DEBUG: Indice=1, Confidenza calcolata=0.9999648332595825, Etichetta=ingegneria_esterno\n",
            "\n",
            "DEBUG Immagine 2: Copia di download (1).jpg\n",
            "DEBUG: Predizione grezza (pred): [2.4646604e-06 9.9999750e-01]\n",
            "DEBUG: Tipo di pred: <class 'numpy.ndarray'>\n",
            "DEBUG: Shape di pred: (2,)\n",
            "DEBUG: Valore confidenza grezza (pred[label_idx]): 0.9999974966049194\n",
            "DEBUG: Indice=1, Confidenza calcolata=0.9999974966049194, Etichetta=ingegneria_esterno\n",
            "\n",
            "DEBUG Immagine 3: Copia di download (2).jpg\n",
            "DEBUG: Predizione grezza (pred): [3.6001722e-05 9.9996400e-01]\n",
            "DEBUG: Tipo di pred: <class 'numpy.ndarray'>\n",
            "DEBUG: Shape di pred: (2,)\n",
            "DEBUG: Valore confidenza grezza (pred[label_idx]): 0.9999639987945557\n",
            "DEBUG: Indice=1, Confidenza calcolata=0.9999639987945557, Etichetta=ingegneria_esterno\n",
            "\n",
            "DEBUG Immagine 4: Copia di download (3).jpg\n",
            "DEBUG: Predizione grezza (pred): [1.4112063e-05 9.9998593e-01]\n",
            "DEBUG: Tipo di pred: <class 'numpy.ndarray'>\n",
            "DEBUG: Shape di pred: (2,)\n",
            "DEBUG: Valore confidenza grezza (pred[label_idx]): 0.999985933303833\n",
            "DEBUG: Indice=1, Confidenza calcolata=0.999985933303833, Etichetta=ingegneria_esterno\n",
            "DEBUG: Fine ciclo processamento predizioni immagini.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting frames from Copia di Copia di timelapse_chiostro.mov: 100%|██████████| 766/766 [00:50<00:00, 15.11it/s]\n",
            "2025-05-09 07:47:10,053 INFO: Estratti 16 frame da Copia di Copia di timelapse_chiostro.mov in /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/temp_frames/Copia di Copia di timelapse_chiostro\n",
            "2025-05-09 07:47:10,120 WARNING: Nessun frame valido dopo preprocessing per Copia di Copia di timelapse_chiostro.mov. Salto.\n",
            "2025-05-09 07:47:10,148 INFO: Processando video: Copia di Copia di timelapse_chiostro_2.mp4\n",
            "Extracting frames from Copia di Copia di timelapse_chiostro_2.mp4: 100%|██████████| 450/450 [00:36<00:00, 12.49it/s]\n",
            "2025-05-09 07:47:47,734 INFO: Estratti 18 frame da Copia di Copia di timelapse_chiostro_2.mp4 in /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/temp_frames/Copia di Copia di timelapse_chiostro_2\n",
            "2025-05-09 07:47:47,762 WARNING: Nessun frame valido dopo preprocessing per Copia di Copia di timelapse_chiostro_2.mp4. Salto.\n",
            "2025-05-09 07:47:47,790 INFO: Inferenza Video Completata\n",
            "2025-05-09 07:47:47,792 INFO: Processo di Inferenza Concluso\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Esecuzione Blocco Principale Terminata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCCO DI CONFIGURAZIONE PER LA MODALITÀ 'TRAIN'\n",
        "# Questo blocco crea un oggetto 'args' che simula gli argomenti\n",
        "# che verrebbero passati da riga di comando allo script.\n",
        "\n",
        "# Verifica che le costanti globali e i percorsi di default siano definiti.\n",
        "# Se hai eseguito le celle precedenti, dovrebbero esserlo.\n",
        "# Esempio di controllo (opzionale, ma utile per debug):\n",
        "# try:\n",
        "#     print(f\"Valore di DEFAULT_TRAIN_DIR: {DEFAULT_TRAIN_DIR}\")\n",
        "#     print(f\"Valore di DEFAULT_OUTPUT: {DEFAULT_OUTPUT}\")\n",
        "#     print(f\"Valore di EPOCHS_HEAD: {EPOCHS_HEAD}\")\n",
        "# except NameError as e:\n",
        "#     print(f\"ERRORE: Una costante o percorso di default non è definito: {e}\")\n",
        "#     print(\"Assicurati di aver eseguito tutte le celle di configurazione precedenti.\")\n",
        "#     raise # Interrompe l'esecuzione se mancano\n",
        "\n",
        "\n",
        "# Creazione dell'oggetto args specifico per il training\n",
        "args_train_config = SimpleNamespace(\n",
        "    # Percorsi per i dati di training e validazione\n",
        "    # Usa i percorsi di default che dovrebbero essere già stati configurati\n",
        "    # per puntare al tuo Google Drive.\n",
        "    train_dir=str(DEFAULT_TRAIN_DIR),\n",
        "    val_dir=str(DEFAULT_VAL_DIR),   # La funzione train() gestirà il caso in cui\n",
        "                                    # questa directory non esista o sia None,\n",
        "                                    # usando uno split dal train_dir.\n",
        "\n",
        "    # Percorso per l'output del training (modello, log, ecc.)\n",
        "    output=DEFAULT_OUTPUT,\n",
        "\n",
        "    # Parametri per le epoche di training\n",
        "    epochs_head=EPOCHS_HEAD,\n",
        "    epochs_fine=EPOCHS_FINE,\n",
        "\n",
        "    # Learning rates (anche se LEARN_HEAD_LR è usato globalmente in build_model,\n",
        "    # includerlo qui è buona pratica se si volesse modificare build_model)\n",
        "    learn_head_lr=LEARN_HEAD_LR,\n",
        "    learn_full_lr=LEARN_FULL_LR\n",
        ")\n",
        "\n",
        "# Stampa di verifica dei parametri impostati per il training (opzionale)\n",
        "print(\"--- Parametri per il Training ---\")\n",
        "print(f\"Directory Training: {args_train_config.train_dir}\")\n",
        "print(f\"Directory Validazione: {args_train_config.val_dir}\")\n",
        "print(f\"Directory Output: {args_train_config.output}\")\n",
        "print(f\"Epoche Training Testa: {args_train_config.epochs_head}\")\n",
        "print(f\"Epoche Fine-Tuning: {args_train_config.epochs_fine}\")\n",
        "print(f\"Learning Rate Testa: {args_train_config.learn_head_lr}\")\n",
        "print(f\"Learning Rate Fine-Tuning: {args_train_config.learn_full_lr}\")\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Chiamata alla funzione di training\n",
        "print(\"\\nAvvio del processo di training...\")\n",
        "try:\n",
        "    # Assicurarsi che la funzione 'train' sia definita\n",
        "    train(args_train_config)\n",
        "    print(\"\\nProcesso di training terminato.\")\n",
        "except NameError:\n",
        "    print(\"ERRORE: La funzione 'train' non è definita. Assicurati di aver eseguito la cella con la sua definizione.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERRORE INASPETTATO durante il training: {e}\")\n",
        "    # Per un traceback più dettagliato in caso di errore\n",
        "    # traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0yXrqBX9jQr",
        "outputId": "64e8f916-69a9-4311-e71a-2188efab3bfd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:47:47,803 INFO: Logging configurato. Log salvati in: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/run.log\n",
            "2025-05-09 07:47:47,839 INFO: --- Inizio Processo di Training ---\n",
            "2025-05-09 07:47:47,843 INFO: Uso directory separata per validazione: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/val\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Parametri per il Training ---\n",
            "Directory Training: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/train\n",
            "Directory Validazione: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/val\n",
            "Directory Output: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output\n",
            "Epoche Training Testa: 8\n",
            "Epoche Fine-Tuning: 4\n",
            "Learning Rate Testa: 0.001\n",
            "Learning Rate Fine-Tuning: 0.0001\n",
            "---------------------------------\n",
            "\n",
            "Avvio del processo di training...\n",
            "Found 65 files belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:47:49,798 INFO: Dataset creato da /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/train. Classi trovate: ['chiostro_esterno', 'ingegneria_esterno']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 27 files belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:47:50,417 INFO: Dataset creato da /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/val. Classi trovate: ['chiostro_esterno', 'ingegneria_esterno']\n",
            "2025-05-09 07:47:50,433 INFO: Numero classi: 2 - Nomi: ['chiostro_esterno', 'ingegneria_esterno']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:47:52,099 INFO: Congelamento 175 layer del backbone ResNet50.\n",
            "2025-05-09 07:47:52,108 INFO: Modello compilato per training testa.\n",
            "2025-05-09 07:47:52,109 INFO: --- Training testa per 8 epoche (LR=0.001) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.8030 - loss: 0.4271 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:49:22,365 WARNING: You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 29s/step - accuracy: 0.8099 - loss: 0.4163 - val_accuracy: 0.4074 - val_loss: 2.3822\n",
            "Epoch 2/8\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9690 - loss: 0.1438 - val_accuracy: 0.4074 - val_loss: 3.1836\n",
            "Epoch 3/8\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9768 - loss: 0.1603 - val_accuracy: 0.4074 - val_loss: 3.4000\n",
            "Epoch 4/8\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9612 - loss: 0.1988 - val_accuracy: 0.4074 - val_loss: 3.1104\n",
            "Epoch 5/8\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9690 - loss: 0.1213 - val_accuracy: 0.4074 - val_loss: 2.6473\n",
            "Epoch 6/8\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.9884 - loss: 0.0421 - val_accuracy: 0.4074 - val_loss: 2.1349\n",
            "Epoch 7/8\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9806 - loss: 0.0317 - val_accuracy: 0.4074 - val_loss: 1.6236\n",
            "Epoch 8/8\n",
            "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0130  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:51:35,947 WARNING: You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.4815 - val_loss: 1.2954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:51:47,521 INFO: Training testa completato.\n",
            "2025-05-09 07:51:47,532 INFO: Caricamento del miglior modello dal training della testa da /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/model_head_best.h5\n",
            "2025-05-09 07:51:49,025 WARNING: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2025-05-09 07:51:49,034 INFO: --- Fine-tuning completo: Sblocco layer ---\n",
            "2025-05-09 07:51:49,040 INFO: Layer trainabili dopo sblocco: 125\n",
            "2025-05-09 07:51:49,047 INFO: Modello ricompilato per fine-tuning (LR=0.0001)\n",
            "2025-05-09 07:51:49,049 INFO: --- Fine-tuning per max 4 epoche (LR=0.0001) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0072   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:52:45,325 WARNING: You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 9s/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.4074 - val_loss: 29.7159\n",
            "Epoch 2/4\n",
            "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.9531 - loss: 1.4491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:52:54,474 WARNING: You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.9612 - loss: 1.2002 - val_accuracy: 0.6296 - val_loss: 1.3805\n",
            "Epoch 3/4\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6002 - loss: 2.1300 - val_accuracy: 0.4074 - val_loss: 12.1533\n",
            "Epoch 4/4\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9690 - loss: 0.3458 - val_accuracy: 0.4074 - val_loss: 11.5240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:53:17,692 INFO: Fine-tuning completato.\n",
            "2025-05-09 07:53:17,720 INFO: Salvataggio del miglior modello dal fine-tuning (/content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/model_fine_tuned_best.h5) come modello finale.\n",
            "2025-05-09 07:53:17,722 INFO: Uso del checkpoint salvato da ModelCheckpoint: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/model_fine_tuned_best.h5\n",
            "2025-05-09 07:53:17,729 INFO: Modello finale salvato in: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/place_model.h5\n",
            "2025-05-09 07:53:17,742 INFO: Mappatura classi salvata in: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/class_indices.csv\n",
            "2025-05-09 07:53:17,743 INFO: --- Processo di Training Concluso ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processo di training terminato.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Configurazione per la MODALITÀ 'INFER'\n",
        "args_infer_config = SimpleNamespace(\n",
        "    # Percorsi per i dati di input per l'inferenza\n",
        "    # Usa i percorsi di default che dovrebbero essere già stati configurati\n",
        "    img_dir=str(DEFAULT_IMG_DIR),\n",
        "    vid_dir=str(DEFAULT_VID_DIR),\n",
        "\n",
        "    # Percorso dove si trova il modello allenato e dove salvare i risultati\n",
        "    output=DEFAULT_OUTPUT,\n",
        "    csv_path=DEFAULT_CSV, # Percorso per il file CSV dei risultati\n",
        "\n",
        "    # Parametri specifici dell'inferenza\n",
        "    # Questi dovrebbero usare le costanti globali che hai definito all'inizio\n",
        "    frame_interval=FRAME_INTERVAL,\n",
        "    sharpness_threshold=SHARPNESS_THRESHOLD,\n",
        "    frames_per_place=FRAMES_PER_PLACE_PER_VIDEO,\n",
        "\n",
        "    # Parametri Google Sheets (se vuoi riattivarli)\n",
        "    # Lascia a None se non li usi\n",
        "    spreadsheet_id=None, # Esempio: \"IL_TUO_SPREADSHEET_ID_QUI\"\n",
        "    sheet_name=\"RisultatiInferenza\" # Nome del foglio su cui scrivere\n",
        ")\n",
        "\n",
        "# Stampa di verifica dei parametri impostati per l'inferenza\n",
        "print(\"Parametri per l'Inferenza:\")\n",
        "print(f\"Directory Immagini Input: {args_infer_config.img_dir}\")\n",
        "print(f\"Directory Video Input: {args_infer_config.vid_dir}\")\n",
        "print(f\"Directory Output (modello/risultati): {args_infer_config.output}\")\n",
        "print(f\"File CSV Risultati: {args_infer_config.csv_path}\")\n",
        "print(f\"Intervallo Frame Video (s): {args_infer_config.frame_interval}\")\n",
        "print(f\"Soglia Nitidezza Frame: {args_infer_config.sharpness_threshold}\")\n",
        "print(f\"Frame Migliori da Salvare per Luogo/Video: {args_infer_config.frames_per_place}\")\n",
        "if args_infer_config.spreadsheet_id:\n",
        "    print(f\"Spreadsheet ID: {args_infer_config.spreadsheet_id}\")\n",
        "    print(f\"Sheet Name: {args_infer_config.sheet_name}\")\n",
        "\n",
        "\n",
        "# Chiamata alla funzione di inferenza\n",
        "print(\"\\nAvvio del processo di inferenza...\")\n",
        "try:\n",
        "    # Assicurarsi che la funzione 'infer' sia definita\n",
        "    infer(args_infer_config)\n",
        "    print(\"\\nProcesso di inferenza terminato.\")\n",
        "except NameError as e:\n",
        "    print(f\"ERRORE: La funzione 'infer' (o una dipendenza) non è definita: {e}. Assicurati di aver eseguito tutte le celle di definizione.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERRORE INASPETTATO durante l'inferenza: {e}\")\n",
        "    # Per un traceback più dettagliato in caso di errore\n",
        "import traceback\n",
        "traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RkiGQBtKWw9",
        "outputId": "81081662-ea8f-4dad-810a-e48ee1289db6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:53:17,776 INFO: Logging configurato. Log salvati in: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/run.log\n",
            "2025-05-09 07:53:17,778 INFO: --- Inizio Processo di Inferenza ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parametri per l'Inferenza:\n",
            "Directory Immagini Input: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG\n",
            "Directory Video Input: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputVID\n",
            "Directory Output (modello/risultati): /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output\n",
            "File CSV Risultati: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/results.csv\n",
            "Intervallo Frame Video (s): 1\n",
            "Soglia Nitidezza Frame: 80.0\n",
            "Frame Migliori da Salvare per Luogo/Video: 5\n",
            "\n",
            "Avvio del processo di inferenza...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-09 07:53:18,857 WARNING: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2025-05-09 07:53:18,892 INFO: Modello caricato da /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/place_model.h5\n",
            "2025-05-09 07:53:18,897 INFO: Classi caricate: ['chiostro_esterno', 'ingegneria_esterno']\n",
            "2025-05-09 07:53:18,902 INFO: File CSV pronto: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/results.csv\n",
            "2025-05-09 07:53:18,904 INFO: Inferenza immagini in: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG\n",
            "2025-05-09 07:53:18,910 INFO: Trovate 5 immagini.\n",
            "2025-05-09 07:53:18,924 INFO: Nessuna nuova immagine valida trovata.\n",
            "2025-05-09 07:53:18,925 INFO: Inferenza video in: /content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputVID\n",
            "2025-05-09 07:53:18,928 INFO: Trovati 2 video.\n",
            "2025-05-09 07:53:18,931 INFO: Processando video: Copia di Copia di timelapse_chiostro.mov\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DEBUG: Inizio ciclo filtro immagini...\n",
            "DEBUG 1/5: Processando 'Copia di 1630611238845.jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di 1630611238845.jpg'\n",
            "DEBUG 1: Risultato is_already_processed: True\n",
            "DEBUG 1: Immagine saltata perché già processata.\n",
            "DEBUG 2/5: Processando 'Copia di 40_Santa_Maria_delle_Grazie.jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di 40_Santa_Maria_delle_Grazie.jpg'\n",
            "DEBUG 2: Risultato is_already_processed: True\n",
            "DEBUG 2: Immagine saltata perché già processata.\n",
            "DEBUG 3/5: Processando 'Copia di download (1).jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (1).jpg'\n",
            "DEBUG 3: Risultato is_already_processed: True\n",
            "DEBUG 3: Immagine saltata perché già processata.\n",
            "DEBUG 4/5: Processando 'Copia di download (2).jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (2).jpg'\n",
            "DEBUG 4: Risultato is_already_processed: True\n",
            "DEBUG 4: Immagine saltata perché già processata.\n",
            "DEBUG 5/5: Processando 'Copia di download (3).jpg' - Key: 'IMG::/content/drive/MyDrive/ProgettoClassificazioneLuoghi/dataset/inputIMG/Copia di download (3).jpg'\n",
            "DEBUG 5: Risultato is_already_processed: True\n",
            "DEBUG 5: Immagine saltata perché già processata.\n",
            "\n",
            "DEBUG: Fine ciclo filtro immagini.\n",
            "DEBUG: Lunghezza valid_img_paths_str: 0\n",
            "DEBUG: Lunghezza original_img_paths: 0\n",
            "DEBUG: Entrando nel blocco 'else'. Nessuna nuova immagine valida trovata.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting frames from Copia di Copia di timelapse_chiostro.mov: 100%|██████████| 766/766 [01:03<00:00, 12.13it/s]\n",
            "2025-05-09 07:54:22,231 INFO: Estratti 16 frame da Copia di Copia di timelapse_chiostro.mov in /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/temp_frames/Copia di Copia di timelapse_chiostro\n",
            "2025-05-09 07:54:22,263 WARNING: Nessun frame valido dopo preprocessing per Copia di Copia di timelapse_chiostro.mov. Salto.\n",
            "2025-05-09 07:54:22,290 INFO: Processando video: Copia di Copia di timelapse_chiostro_2.mp4\n",
            "Extracting frames from Copia di Copia di timelapse_chiostro_2.mp4: 100%|██████████| 450/450 [00:34<00:00, 12.87it/s]\n",
            "2025-05-09 07:54:57,523 INFO: Estratti 18 frame da Copia di Copia di timelapse_chiostro_2.mp4 in /content/drive/MyDrive/ProgettoClassificazioneLuoghi/output/temp_frames/Copia di Copia di timelapse_chiostro_2\n",
            "2025-05-09 07:54:57,563 WARNING: Nessun frame valido dopo preprocessing per Copia di Copia di timelapse_chiostro_2.mp4. Salto.\n",
            "2025-05-09 07:54:57,591 INFO: Inferenza Video Completata\n",
            "2025-05-09 07:54:57,594 INFO: Processo di Inferenza Concluso\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processo di inferenza terminato.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "NoneType: None\n"
          ]
        }
      ]
    }
  ]
}